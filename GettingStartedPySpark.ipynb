{"metadata":{"language_info":{"name":"pyspark","mimetype":"text/x-python","codemirror_mode":{"name":"python","version":3},"pygments_lexer":"python3"},"kernelspec":{"name":"pysparkkernel","display_name":"PySpark","language":""},"qubole":{"kernel_log_url":"https://quickfix.qa.qubole.net/jupyter-notebook-8329/qubole/api/v1/kernel_logs/262dc9b3-34c7-4e31-a630-7649a95f3c7f","session_data":{"id":0,"mode":"scoped","spark_ui_url":"/cluster-proxy?clusterInst=13037\u0026encodedUrl=http%3A%2F%2F172.31.12.14%3A8088%2Fproxy%2Fapplication_1596542779089_0001%2F%3Fspark%3Dtrue","driver_log_url":"/cluster-proxy?clusterInst=13037\u0026encodedUrl=http%3A%2F%2F172.31.12.8%3A8042%2Fnode%2Fcontainerlogs%2Fcontainer_1596542779089_0001_01_000001%2Fvarshar"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" ## This is a pyspark example notebook along with sql\n- Supported magics can be found via %%help\n- %%markdown: markdown or Select \"Markdown\" from Cell type dropdown\n- %%sql: sql on spark\n- %%bash or %%sh: shell\n- %%local: Execution in kernel\n- %%configure: Can be used to configure Spark settings","metadata":{}},{"cell_type":"markdown","source":"### Run spark command\n- SparkContext is available as sc\n- Spark application is started lazily on the first Spark command run","metadata":{}},{"cell_type":"code","source":"sc.version","metadata":{"qubole":{},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### pyspark Pi Calculation example","metadata":{}},{"cell_type":"code","source":"from random import random\nfrom operator import add\npartitions = 10\nn = 100000 * partitions\n\ndef f(_):\n    x = random() * 2 - 1\n    y = random() * 2 - 1\n    return 1 if x ** 2 + y ** 2 \u003c 1 else 0\n\ncount = sc.parallelize(range(1, n + 1), partitions).map(f).reduce(add)\nprint(\"Pi is roughly %f\" % (4.0 * count / n))","metadata":{"qubole":{},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### sql example","metadata":{}},{"cell_type":"code","source":"%%sql\nshow tables","metadata":{"qubole":{},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Alternate way to use spark sql\nsqlContext.sql(\"show tables\").collect()","metadata":{"qubole":{},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%sql\nselect * from default_qubole_memetracker limit 10","metadata":{"qubole":{},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizations on airline data for four quarters","metadata":{}},{"cell_type":"code","source":"%%sql\nselect origin, quarter, count(*)/1000000 count from default_qubole_airline_origin_destination\n  where quarter is not NULL group by origin, quarter order by count desc limit 100\n","metadata":{"qubole":{},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Matplotlib example using store and local magic\n- The -o parameter stores the data in the specified variable in the kernel\n- The number of rows to be retrived can be specified using -n parameter","metadata":{}},{"cell_type":"code","source":"%%sql -o data -n 10 -q\nselect * from default_qubole_airline_origin_destination","metadata":{"qubole":{},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Matplotlib can be used alongwith %%local to plot stored data","metadata":{}},{"cell_type":"code","source":"%%local\n%matplotlib inline\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata['distance'] = pd.to_numeric(data['distance'], errors='coerce')\ndata.plot(kind='bar', x='dest', y='distance', color='blue')\n\nplt.show()","metadata":{"qubole":{},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Matplotlib example using matplot line magic","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport pandas as pd\n\nplt.figure(num=None, figsize=(10, 10), dpi=100)\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/arangodb/example-datasets/master/Cities/GeoLiteCity.csv\")\n\ncol1 = df['longitude']\ncol2 = df['latitude']\nplt.scatter(col1, col2, edgecolors='r')","metadata":{"qubole":{},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplot plt","metadata":{"qubole":{},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transferring data from spark to local kernel\n\nA dataframe can also be transferred from a non %%sql cell to %%local cell using the %spark line magic. An example is shown below.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\npdf = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/1962_2006_walmart_store_openings.csv\")\nsdf = spark.createDataFrame(pdf.astype(str))","metadata":{"qubole":{},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%spark -o sdf","metadata":{"qubole":{},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%local\n%matplotlib inline\nsdf.groupby('YEAR').count()['storenum'].plot.line()","metadata":{"qubole":{},"trusted":true},"execution_count":null,"outputs":[]}]}